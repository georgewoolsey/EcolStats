---
title: "ECOL 592: ANOVA and Regression"
author: "George Woolsey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    toc: true
    toc_depth: 3
linkcolor: blue
header-includes:
  - \usepackage{caption}
  - \captionsetup[figure]{labelformat=empty}
editor_options: 
  chunk_output_type: console
knit: (function(inputFile, encoding){ 
    out_dir <- '/data';
    rmarkdown::render(inputFile, encoding = encoding, output_file=file.path(dirname(inputFile), out_dir, 'ECOL592_Wk3_GWoolsey.pdf')) 
  })
---

```{r setup, include=F}
# knit options
knitr::opts_chunk$set(
  echo = TRUE
  , warning = FALSE
  , message = FALSE
  , fig.height = 5
  , fig.width = 7
  , eval = TRUE
  , fig.align='center'
)
# load libraries
# bread-and-butter
library(tidyverse)
library(lubridate)
library(viridis)
library(scales)
library(latex2exp)
# visualization
library(cowplot)
library(kableExtra)
```

# ANOVA

Interpret the result of ANOVA and tell how much of the variability in corn yield is explained by variety? Use below formula to compute R-square. Interpret the Levenes test.

$$R^2 =1-\frac{Residuals  Sum Sq}{Variety Sum Sq + Residuals Sum Sq}$$


```{r}
Corn <- read.csv("data/CornYield.csv", quote = "'") %>% 
  dplyr::mutate(Variety = factor(Variety))
boxplot(Yield~Variety,data=Corn, xlab = "Varieties", ylab = "Yield", main = "Histogram of Corn yield")
lm_yld_vrty <- lm(Yield~Variety, data = Corn)
anova(lm_yld_vrty)
library(car)
levene_test <- car::leveneTest(Yield~Variety, data = Corn)
levene_test
# values for answer
r_sq <- summary(lm_yld_vrty)$r.squared %>% scales::percent(accuracy = 0.1)
p_val <- levene_test$`Pr(>F)`[1]
```

## Response

The results of the linear model of corn yield on corn variety indicate that there are statistically significant differences between at least two varieties in yield. The $R^2$ of the model is `r r_sq`, which means that corn variety explains `r r_sq` of the variation in corn yield. In Levene's test the null hypothesis is that there is homogeneity of variance across the groups; a p-value of `r p_val` means that we fail to reject the null hypothesis that the variance is homogeneous across groups.

# Mean comparisons

According to mean Comparisons, which variety(s) has the statistically significant highest yield?

```{r}
# we can compare the means with a linear model using variety represented as a factor
summary(lm_yld_vrty)
# get lm estimates in df
intercept <- summary(lm_yld_vrty)$coefficients[1]
x_nm <- summary(lm_yld_vrty)$coefficients %>% row.names() %>% stringr::str_remove("Variety")
vars <- Corn$Variety %>% unique() %>% as.character()
df_estimates <- summary(lm_yld_vrty)$coefficients %>% 
  dplyr::as_tibble() %>% 
  dplyr::mutate(
    x = x_nm
    , mean_est = ifelse(x == "(Intercept)", Estimate, intercept + Estimate)
    , Variety = ifelse(x == "(Intercept)", vars[!vars %in% x_nm], x) %>% as.factor()
  )
# plot
ggplot(data = df_estimates, mapping = aes(x = Variety, y = mean_est, fill = Variety)) +
  geom_col(alpha = 0.6, width = 0.6) +
  geom_point(
    data = Corn
    , mapping = aes(x=Variety, y=Yield, fill = Variety)
    , shape = 21
    , size = 3
    , alpha = 1
  ) +
  geom_text(mapping = aes(label=scales::comma(mean_est,accuracy=0.1), fontface="bold"), vjust = 0, size = 8) +
  scale_fill_viridis_d(option="cividis") +
  labs(x = "Variety", y = "Yield", subtitle = "Mean of Yield by Variety") +
  theme_bw() +
  theme(legend.position = "none")
# we can double check these estimates
Corn %>% 
  dplyr::group_by(Variety) %>% 
  dplyr::summarise(mean_yield = mean(Yield, na.rm=T) %>% scales::comma(accuracy = 0.1))
```

## Response

The mean of yield by variety is presented in the figure and table above. A "dummy variable" regression returns mean estimates by group where the intercept is a baseline group not included in the model.

## Alternative

the package `emmeans` provides options to retrieve estimated marginal means

```{r, include=TRUE,eval=FALSE}
library(emmeans)
Comparison <- emmeans::emmeans(lm_yld_vrty, ~ Variety)
pairs(Comparison, adjust = "tukey")
plot(pairs(Comparison,adjust = "tukey"), horizontal=F)
```

# Regression

Interpret the regression results.What does the number 11.4593 mean in the results table (in front of Height)? What does R-square mean? Interpret Breusch-Pagan test (Uncomment "lmtest" installation if you don't have the package).

```{r}
Trees <- read.csv("data/Trees.csv", quote = "'")
attach(Trees)
reg_model <- lm(Age ~ Height, data = Trees)
summary(reg_model)
plot(Age ~ Height, data = Trees)
abline(reg_model, col = "red")
detach(Trees)
#install.packages("lmtest")
library(lmtest)
heteroskedasticity_test <- lmtest::bptest(reg_model)
heteroskedasticity_test
```

## Response

In the regression results, the number `11.4593` is the estimated impact of a one unit increase in tree height on tree age. That is, for every one unit increase in tree height, tree age increases by `11.4593`, all else equal. The $R^2$ value of `r summary(reg_model)$r.squared %>% scales::percent(accuracy = 0.1)` means that tree height explains `r summary(reg_model)$r.squared %>% scales::percent(accuracy = 0.1)` of the variation in tree age. The result of the Breusch-Pagan Test against heteroskedasticity means that we fail to reject the null hypothesis of heteroskedasticity and the resuduals variance is constant across the values of tree height.

